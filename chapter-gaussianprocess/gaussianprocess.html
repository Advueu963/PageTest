
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>10. Gaussian Processes &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/myStyle.css?v=e90502a2" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"N": ["\\mathbb{N}"], "vec": ["\\boldsymbol{#1}", 1], "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"], "defeq": ["\\mathrel{\\vcenter{\\baselineskip0.5ex \\lineskiplimit0pt \\hbox{\\footnotesize.}\\hbox{\\footnotesize.}}}% ="], "given": ["\\, | \\,"], "cX": ["\\mathcal{X}"], "cY": ["\\mathcal{Y}"], "cH": ["\\mathcal{H}"], "cD": ["\\mathcal{D}"], "hath": ["\\hat{h}"], "haty": ["\\hat{y}"], "hatp": ["\\hat{p}"], "sety": ["\\widehat{Y}"], "argmin": ["\\operatorname*{argmin}"], "argmax": ["\\operatorname*{argmax}"], "db": ["\\set{M}"], "fkt": ["#1(\\cdot)", 1], "chrfkt": ["\\mathbb{I}_{#1}", 1], "kref": ["(\\ref{#1})", 1], "convto": ["(\\rightarrow"], "fft": ["(#1 :  #2 \\rightarrow #3", 3], "with": ["\\,  | \\,"], "sothat": ["\\,  : \\,"], "defi": ["\\stackrel{\\on{df}}{=}"], "set": ["\\mathcal{#1}", 1], "Prob": ["P"], "prob": ["p"], "impl": ["\\Rightarrow"], "on": ["\\operatorname"], "groesser": ["\\raisebox{#1mm}{} \\raisebox{-#1mm}{}", 1], "sgroesser": ["\\groesser{1.20}"], "xleftr": ["\\left( \\groesser{1.35} "], "xleftg": ["\\left\\{ \\groesser{1.35} "], "fftm": ["\\fft{#1}{#2}{#3} \\, ,\\, #4 \\mapsto #5", 5], "gdw": ["\\Leftrightarrow"], "gdwbd": ["\\stackrel{\\on{df}}{\\Leftrightarrow}"], "est": ["{est}"], "epd": ["\\Leftrightarrow_{\\on{def}}"], "fromto": ["\\longrightarrow"], "pref": ["\\succ"], "evalue": ["\\mathbf{E}"], "variance": ["\\mathbf{V}"], "mmp": ["", 1], "llbracket": ["\\lbrack\\lbrack"], "rrbracket": ["\\rbrack\\rbrack"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter-gaussianprocess/gaussianprocess';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="11. Deep Neural Network Ensembles" href="../chapter-deep_neuralnetwork/dnn.html" />
    <link rel="prev" title="9. Generative Models" href="../chapter-generative_models/gm.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../startPage.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../startPage.html">
                    Toolbox for Uncertainty Quantification in Machine Learning
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter-prelude/prelude.html">1. Prelude</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter-intro/intro.html">2. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter-srcUncertainty/src.html">3. Sources of uncertainty in supervised learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter-modelingAproxUncertainty/modelingAproxUncertainty.html">4. Modelling Approximation Uncertainty</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter-pe-scoring/scoring.html">5. Probability Estimation via Scoring</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter-pe-calibration/calibration.html">6. Probability Estimation and Calibration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter-pe-ensemble/ensemble.html">7. Probability Estimation and Ensembles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter-mle_and_fisher/mle.html">8. Maximum Likelihood and Fisher Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter-generative_models/gm.html">9. Generative Models</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">10. Gaussian Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter-deep_neuralnetwork/dnn.html">11. Deep Neural Network Ensembles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter-bayesian_neuralnetwork/bayesian.html">12. Bayesian Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter-credal_sets/credal_sets.html">13. Credal Sets and Classifiers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter-reliable_classification/reliable_classification.html">14. Reliable Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter-conformel_classification/conformel_classification.html">15. Conformal Prediction for Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter-conformel_regression/conformel_regression.html">16. Conformal Prediction for Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter-setValued_utilityMaximization/set.html">17. Set-valued Prediction Based on Utility Maximization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter-appendix/appendix.html">18. Appendix</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">19. References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/Advueu963/PageTest/blob/main/chapter-gaussianprocess/gaussianprocess.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/Advueu963/PageTest" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/Advueu963/PageTest/edit/main/chapter-gaussianprocess/gaussianprocess.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/Advueu963/PageTest/issues/new?title=Issue%20on%20page%20%2Fchapter-gaussianprocess/gaussianprocess.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter-gaussianprocess/gaussianprocess.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Gaussian Processes</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="gaussian-processes">
<span id="id1"></span><h1><span class="section-number">10. </span>Gaussian Processes<a class="headerlink" href="#gaussian-processes" title="Link to this heading">#</a></h1>
<p>In this chapter we will consider <em>Gaussian Processes</em> for uncertainty quantification. Our setup is the following:
<br>
We have labeled data <span class="math notranslate nohighlight">\(\mathcal{D} = \{(y_{1}, {\bf x}_{1}),...,(y_{n}, {\bf x}_{n}) \} \subset \mathcal{Y} \times \mathcal{X}\)</span>, where we assume that each observaton is some function of the input, e.g. <span class="math notranslate nohighlight">\(y_{i} = f({\bf x}_{i})\)</span>. Especially we assume we have a (prior-) distribution of possible functions that could give rise to the observed data.Therefore our Hypothesis Space <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> is a set of possible function that could have generated the data. The more data we observe, the narrower is the choice of possible functions that can explain the oberservations. More precisely we assume that the distribution mus be in the family of multivariate Gaussians which leads to the notion of a Gaussian Process.</p>
<div class="proof definition admonition" id="def-gauss-process">
<p class="admonition-title"><span class="caption-number">Definition 10.1 </span></p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\mathcal{I}\)</span> be some index set and let <span class="math notranslate nohighlight">\(S \subset \mathcal{P}(\mathcal{I})\)</span> be finite. Further let <span class="math notranslate nohighlight">\({\bf Y}_{i}\)</span> be iid Gaussian, e.g. <span class="math notranslate nohighlight">\({\bf Y}_{i} \sim \mathcal{N}(\mu, \sigma^{2})\)</span> <span class="math notranslate nohighlight">\(\forall i \in \mathcal{I}\)</span>
The sequence <span class="math notranslate nohighlight">\(({\bf Y}_{i})_{i \in \mathcal{I}}\)</span> is a Gaussian Process if for each <span class="math notranslate nohighlight">\(S\)</span> the finite sequence <span class="math notranslate nohighlight">\(({\bf Y}_{j})_{j \in S}\)</span> is multivariate Gaussian e.g. <span class="math notranslate nohighlight">\({\bf Y}_{s} \sim \mathcal{N}(\mu, \sigma^{2})\)</span> <span class="math notranslate nohighlight">\(\forall s \in S\)</span></p>
</section>
</div><p>Multivariate gaussian distributions are specified via a mean vector and a covariance matrix. For Gaussian Processes the the covariance matrix has a special form: each entry can be expressed as a dot product of the input features <span class="math notranslate nohighlight">\(\bf x\)</span> in some (typically high dimensional)  feature space <span class="math notranslate nohighlight">\(\phi({\bf x})\)</span>. The dot product itself is often not specified but rather a kernel function for two inputs <span class="math notranslate nohighlight">\(k({\bf x}, {\bf x}^{\prime})\)</span>. The covariance function is then defined componentwise as:</p>
<div class="math notranslate nohighlight">
\[{\bf K}_{i,j}= k({\bf x}_{i}, {\bf x}_{j})\]</div>
<p>An example would be the radial basis function <span class="math notranslate nohighlight">\(k({\bf x}_{i}, {\bf x}_{j}) = \text{exp}(\frac{1}{2l}||{\bf x}_{i} - {\bf x}_{j}||^2)\)</span> where one can show that this can be express as some dotproduct <span class="math notranslate nohighlight">\(\phi({\bf x}_{i})^{T} \phi({\bf x}_{j})\)</span> for appropriate definition of <span class="math notranslate nohighlight">\(\phi\)</span>.
To finalize notation we have:</p>
<div class="math notranslate nohighlight">
\[{\bf y} \sim \mathcal{N}({\bf \mu}, {\bf K}), {\bf y} = [f({\bf x})_{1},...,f({\bf x}_{n})]^{T},
{\bf \mu} = [m({\bf x}_{1}),...m({\bf x}_{n})]^{T}\]</div>
<p>The covariance function above has only one hyperparameter, the length scale <span class="math notranslate nohighlight">\(l\)</span> which controls how close two datapoints in the inputspace <span class="math notranslate nohighlight">\(\bf x\)</span> are in outputspac <span class="math notranslate nohighlight">\(\bf y\)</span> (if two points close in input space are close in output space the function will behave less ‘wiggly’). Typically this is not the only hyperparameter but reasonable covariance functions depend on multiple hyperparameters allowing greater fexibility in modelling the depence structure. Also we can allow for noisy observations, e.g. <span class="math notranslate nohighlight">\(y_{i} = f({\bf x}_{i}) + \epsilon\)</span> where <span class="math notranslate nohighlight">\(\epsilon \sim \mathcal{N}(0, \sigma_{\epsilon}^{2})\)</span> by adding gaussian noise <span class="math notranslate nohighlight">\(\sigma^{2}_{n}\)</span> to the covariance function. Using dirac-delta notation the covariance kernel is now:</p>
<div class="math notranslate nohighlight">
\[{\bf K}_{i,j}= k({\bf x}_{i}, {\bf x}_{j}) + \delta_{ij}\sigma^{2}_{\epsilon}\]</div>
<p>Other possible covariance functions are for example the Matérn and Polynomial kernel as well as the periodic :</p>
<div class="math notranslate nohighlight">
\[k_{Mat}({\bf d})= \frac{2^{1-\nu}}{\Gamma(\nu)} \left( \sqrt{2 \nu}d \right)^{\nu} K_{\nu}(\sqrt{2 \nu}d)\]</div>
<div class="math notranslate nohighlight">
\[k_{Poly}({\bf x}_{1}, {\bf x}_{2}) = ({\bf x}_{1}^{T}{\bf x}_{2} + c)^{d}\]</div>
<p>where <span class="math notranslate nohighlight">\(K_{\nu}\)</span> is a modified Bessel-function and <span class="math notranslate nohighlight">\(\Gamma()\)</span> is the gamma function.<br></p>
<p>Since the each <span class="math notranslate nohighlight">\({\bf x}_{i}\)</span> if realization of a random variable we have two variances or standard deviations to consider: The standard devation due to a noisy observation <span class="math notranslate nohighlight">\(\epsilon\)</span>, e.g. <span class="math notranslate nohighlight">\(\sigma_{\epsilon}\)</span> and the standard deviation of each individual posterior predictive Gaussian <span class="math notranslate nohighlight">\(\sigma_{i}\)</span> where <span class="math notranslate nohighlight">\(\sigma_{i}\)</span> captures the total unceratainty and <span class="math notranslate nohighlight">\(\sigma_{\epsilon}\)</span> the aleatoric uncertainty which could be reduced by more observations.<br>
In the following we give an illustration by creating some artifical data. Let us first import the necessary libraries and define some functions for better illustration:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span> <span class="k">as</span> <span class="n">iterprod</span>


<span class="kn">from</span> <span class="nn">scipy.stats</span>  <span class="kn">import</span> <span class="n">norm</span> <span class="k">as</span> <span class="n">normal</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">gaussian_process</span> <span class="k">as</span> <span class="n">gp</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">polynomial_kernel</span>
<span class="kn">from</span> <span class="nn">sklearn.gaussian_process</span> <span class="kn">import</span> <span class="n">GaussianProcessRegressor</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">gpytorch</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">123</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">set_default_dtype</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;seaborn-v0_8-whitegrid&quot;</span><span class="p">)</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.figsize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">float_format</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span>
</pre></div>
</div>
</div>
</div>
<p>We assume the actual data is defined by <span class="math notranslate nohighlight">\(\sin(x) \times \frac{x}{2}\)</span> to which we add some noise drawn from a Gaussian distribution implemented in <code class="docutils literal notranslate"><span class="pre">true_func</span></code> and <code class="docutils literal notranslate"><span class="pre">add_error</span></code>. We also define how many samples to draw and the resolution on for the real numbers we use as input.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">noise</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">x_min</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="n">x_max</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">granularity</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">granularity</span> <span class="o">/</span> <span class="mi">20</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">true_func</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return the actual function value(s).</span>

<span class="sd">    This function takes some input number(s) and create the actual function value, e.g. this function implements $y_{i] = f(x_{i})$.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">x</span>
    
<span class="k">def</span> <span class="nf">add_error</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">noise</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Add Gaussian error terms to input.</span>

<span class="sd">    This function adds some error term drawn from a normal centered at zero with given variance to the input, e.g.:</span>
<span class="sd">    $y_{i} = f(x_{i}) + \epsilon{i}$</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;&gt;:10: SyntaxWarning: invalid escape sequence &#39;\e&#39;
&lt;&gt;:10: SyntaxWarning: invalid escape sequence &#39;\e&#39;
/tmp/ipykernel_4012/2847294952.py:10: SyntaxWarning: invalid escape sequence &#39;\e&#39;
  &quot;&quot;&quot;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_line</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">num</span> <span class="o">=</span> <span class="n">granularity</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">a</span> <span class="o">=</span> <span class="n">x_line</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">replace</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">add_error</span><span class="p">(</span><span class="n">true_func</span><span class="p">(</span><span class="n">x_train</span><span class="p">),</span> <span class="n">noise</span><span class="p">)</span>

<span class="n">y_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;y&quot;</span><span class="p">:</span><span class="n">true_func</span><span class="p">(</span><span class="n">x_line</span><span class="p">)},</span> <span class="n">index</span> <span class="o">=</span> <span class="n">x_line</span><span class="p">),</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;y_train&quot;</span><span class="p">:</span> <span class="n">y_train</span><span class="p">},</span> <span class="n">index</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">)])</span>
</pre></div>
</div>
</div>
</div>
<p>The following block contains functions for plotting which might not be of primary interes.</p>
<div class="cell tag_hide-cell docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">concat_obs</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">y_obs</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_obs</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Typically if we have predictions we want to add the actual observations as well, this is a handy shortcut.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">df_new</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;obs&quot;</span><span class="p">:</span> <span class="n">y_obs</span><span class="p">},</span> <span class="n">index</span> <span class="o">=</span> <span class="n">x_obs</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">df_new</span>


<span class="k">def</span> <span class="nf">plot_gp_frame</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a plot from a dataframe with predictions and observations.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;obs&quot;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;obs&quot;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;obs&quot;</span><span class="p">],</span> <span class="s2">&quot;kx&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;observation&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xaxis</span><span class="p">(</span><span class="s2">&quot;$x$&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yaxis</span><span class="p">(</span><span class="s2">&quot;$f(x)$&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_normal_vals</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">percentile</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">pred_val</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">y_min</span> <span class="o">=</span> <span class="n">true_func</span><span class="p">(</span><span class="n">x_line</span><span class="p">)</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">true_func</span><span class="p">(</span><span class="n">x_line</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Since the predictions of a GP specify a marginal Gaussian distribution for each x this function takes some x values</span>
<span class="sd">    from the nearest given percentile say $x_{j}$ and calculates the corresponding Gaussian $\mathcal{N}(\mu_{j}, \sigma_{j}^2{2}$.</span>
<span class="sd">    The parameters are stored in the given dataframe.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">))</span>
    <span class="k">assert</span><span class="p">(</span><span class="nb">all</span><span class="p">([</span><span class="n">word</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;pred&quot;</span><span class="p">,</span> <span class="s2">&quot;sd&quot;</span><span class="p">]]))</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">percentile</span> <span class="o">&lt;</span> <span class="mi">100</span> <span class="ow">and</span> <span class="n">percentile</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;expected percentile to be in range(0,100), got: </span><span class="si">{</span><span class="n">percentile</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">pred_val</span><span class="p">:</span>
        <span class="c1"># note: x values are the indices of the dataframe</span>
        <span class="n">x_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">x_line</span><span class="p">,</span> <span class="n">percentile</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;nearest&quot;</span><span class="p">)</span>
        <span class="n">query</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">index</span> <span class="o">==</span> <span class="n">x_val</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span><span class="p">(</span><span class="n">pred_val</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">pred</span><span class="p">)</span>
        <span class="n">query</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">pred</span> <span class="o">==</span> <span class="n">pred_val</span><span class="p">]</span>
    
    <span class="k">assert</span><span class="p">(</span><span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">query</span><span class="p">[[</span><span class="s2">&quot;pred&quot;</span><span class="p">,</span> <span class="s2">&quot;sd&quot;</span><span class="p">]]))</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
        
    <span class="n">normal_mean</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">pred</span><span class="o">.</span><span class="n">values</span>
    <span class="n">normal_sd</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">sd</span><span class="o">.</span><span class="n">values</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">normal</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="n">normal_mean</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="n">normal_sd</span><span class="p">)</span>

    <span class="n">y_values</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span>  <span class="mi">1000</span><span class="p">)</span>
    <span class="n">x_values</span> <span class="o">=</span> <span class="n">n</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">y_values</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">x_values</span> <span class="o">+</span> <span class="n">x_val</span> <span class="p">,</span> <span class="n">y_values</span>

<span class="k">def</span> <span class="nf">plot_normals</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">percentiles</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plot density of the marginal Gaussian for some values to the nearest given percentiles.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">percentile</span> <span class="ow">in</span> <span class="n">percentiles</span><span class="p">:</span>
        <span class="n">x_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">percentile</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;nearest&quot;</span><span class="p">)</span>
        <span class="n">mean_val</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">x_val</span><span class="p">]</span><span class="o">.</span><span class="n">pred</span>

        <span class="n">x_vals</span><span class="p">,</span> <span class="n">y_vals</span> <span class="o">=</span> <span class="n">get_normal_vals</span><span class="p">(</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">,</span> <span class="n">percentile</span> <span class="o">=</span> <span class="n">percentile</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">mean_val</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">mean_val</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="n">mean_val</span><span class="p">,</span> <span class="n">xmin</span> <span class="o">=</span> <span class="n">x_val</span><span class="p">,</span> <span class="n">xmax</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">x_vals</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.0001</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        

<span class="k">def</span> <span class="nf">get_model_vals</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_line</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a DataFrame with marginal means and standarddeviations.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pred_mean</span><span class="p">,</span> <span class="n">pred_sd</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_line</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">return_std</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;pred&quot;</span><span class="p">:</span> <span class="n">pred_mean</span><span class="p">,</span> <span class="s2">&quot;sd&quot;</span><span class="p">:</span> <span class="n">pred_sd</span><span class="p">},</span><span class="n">index</span> <span class="o">=</span> <span class="n">x_line</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">data</span>


<span class="k">def</span> <span class="nf">get_rbf_preds</span><span class="p">(</span><span class="n">lengthscale</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">as_frame</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">optimize</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fit a GP model with a RBF Kernel and return results in DataFrame.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">kernel</span> <span class="o">=</span> <span class="n">gp</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">RBF</span><span class="p">(</span><span class="n">length_scale</span> <span class="o">=</span> <span class="n">lengthscale</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="n">noise</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span><span class="n">n_restarts_optimizer</span> <span class="o">=</span> <span class="mi">9</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">get_model_vals</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_line</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">as_frame</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">data</span>
        
    <span class="k">return</span> <span class="n">data</span><span class="o">.</span><span class="n">pred</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">sd</span><span class="o">.</span><span class="n">values</span>
    
<span class="k">def</span> <span class="nf">get_matern_preds</span><span class="p">(</span><span class="n">lengthscale</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">as_frame</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">optimize</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fit a GP model with a Matern Kernel and return results in DataFrame.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">kernel</span> <span class="o">=</span> <span class="n">gp</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span> <span class="o">=</span> <span class="n">lengthscale</span><span class="p">,</span> <span class="n">nu</span> <span class="o">=</span> <span class="n">nu</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="n">noise</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_restarts_optimizer</span> <span class="o">=</span> <span class="mi">9</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">get_model_vals</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_line</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">as_frame</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">data</span>
        
    <span class="k">return</span> <span class="n">data</span><span class="o">.</span><span class="n">pred</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">sd</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;&gt;:21: SyntaxWarning: invalid escape sequence &#39;\m&#39;
&lt;&gt;:21: SyntaxWarning: invalid escape sequence &#39;\m&#39;
/tmp/ipykernel_4012/2768479145.py:21: SyntaxWarning: invalid escape sequence &#39;\m&#39;
  &quot;&quot;&quot;
</pre></div>
</div>
</div>
</details>
</div>
<p>The plot below illustrates the data we just generated:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y_data</span><span class="p">[</span><span class="s2">&quot;y_train&quot;</span><span class="p">],</span> <span class="s2">&quot;rx&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$y_</span><span class="si">{obs}</span><span class="s2"> = f(x_</span><span class="si">{obs}</span><span class="s2">) + \epsilon$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y_data</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span>  <span class="s2">&quot;k-&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$f(x)$&quot;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s2">&quot;lower left&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$f(x)$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Actual function and noise observations&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s2">&quot;upper left&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9773c98bc38f2fe1fbc4950cd2b5d99e5e82e8be6bd8a873dc8ef4141741eb85.png" src="../_images/9773c98bc38f2fe1fbc4950cd2b5d99e5e82e8be6bd8a873dc8ef4141741eb85.png" />
</div>
</div>
<p>Given our observations we can fit a Gaussian Process using maximum Likelihood methods. For that we have to specify the kernel (including) hyperparameters) and the Gaussian noise which contanimnates our observations. <br>
The plot below shows the actual function, the noise observations and the mean preadictions. Since for prediction we do not have a scalar value but a distribution a natural choice is to use its mean value for pre</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">length_scale</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">noise_sd</span> <span class="o">=</span> <span class="mf">1.0</span>

<span class="n">kernel</span> <span class="o">=</span> <span class="n">gp</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">RBF</span><span class="p">(</span><span class="n">length_scale</span> <span class="o">=</span> <span class="n">length_scale</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="n">noise_sd</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span><span class="n">n_restarts_optimizer</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">get_model_vals</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_line</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">concat_obs</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">percentiles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span>  <span class="mi">70</span><span class="p">,</span> <span class="mi">90</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;pred&quot;</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;mean prediction, $\overline</span><span class="si">{f}</span><span class="s2">(x)$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;obs&quot;</span><span class="p">],</span> <span class="s2">&quot;rx&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;observation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y_data</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> <span class="s2">&quot;k-&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$f(x) =\sin (x)$&quot;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="n">plot_normals</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">percentiles</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span> <span class="s2">&quot;color&quot;</span><span class="p">:</span><span class="s2">&quot;g&quot;</span><span class="p">,</span> <span class="s2">&quot;linestyle&quot;</span><span class="p">:</span> <span class="s2">&quot;-&quot;</span><span class="p">})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Gaussian Process with RBF-Kernel $l$=l_scale amd $\sigma_{\epsilon}$=n_sd&quot;</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;l_scale&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">length_scale</span><span class="p">))</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;n_sd&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">noise_sd</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$x$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$f(x)$,  $\overline</span><span class="si">{f}</span><span class="s2">(x)$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s2">&quot;upper left&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/e2e22cb07d79a7daf442790e20436f227f374753cbdaddc1dde6bda3005c54dd.png" src="../_images/e2e22cb07d79a7daf442790e20436f227f374753cbdaddc1dde6bda3005c54dd.png" />
</div>
</div>
<p>Depending on how noisy we assume our observations to be, the more each observation can deviate from the mean prediction of it and the less accurate the resulting Gaussian Process interpolates between the observation. The plots below illustrate this for a radial basis function kernel as well as a matern kernel (which seems to not deviate much from each other).</p>
<div class="cell tag_hide-cell docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gp_ax_plot</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">xlabel</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$x$&quot;</span><span class="p">,</span> <span class="n">ylabel</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$\overline</span><span class="si">{f}</span><span class="s2">(x)$&quot;</span><span class="p">,</span> <span class="n">lscales</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">nuscales</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plot the result of fitting a Gaussian Process on some data with help of the functions defined above.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">get_rbf_preds</span><span class="p">(</span><span class="n">lengthscale</span> <span class="o">=</span> <span class="n">lscales</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">noise</span> <span class="o">=</span> <span class="n">noise</span><span class="p">,</span> <span class="n">as_frame</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">pred</span><span class="p">,</span>
         <span class="s2">&quot;-&quot;</span><span class="p">,</span>
         <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;orange&quot;</span><span class="p">,</span>
         <span class="n">label</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$RBF(l=l_scale)$&quot;</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;l_scale&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">lscales</span><span class="p">[</span><span class="mi">0</span><span class="p">])),</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">get_matern_preds</span><span class="p">(</span><span class="n">lengthscale</span> <span class="o">=</span> <span class="n">lscales</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">nu</span> <span class="o">=</span> <span class="n">nuscales</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">noise</span> <span class="o">=</span> <span class="n">noise</span><span class="p">,</span> <span class="n">as_frame</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">pred</span><span class="p">,</span>
         <span class="s2">&quot;-&quot;</span><span class="p">,</span>
         <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;blue&quot;</span><span class="p">,</span>
         <span class="n">label</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$Matern(l=l_scale,\nu=nu_scale)$&quot;</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;l_scale&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">lscales</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;nu_scale&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">nuscales</span><span class="p">[</span><span class="mi">0</span><span class="p">])),</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;obs&quot;</span><span class="p">],</span> <span class="s2">&quot;rx&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;observation&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y_data</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> <span class="s2">&quot;k-&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$f(x) =\sin (x)$&quot;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s2">&quot;upper left&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">gp_ax_plot</span><span class="p">(</span><span class="n">noise</span> <span class="o">=</span> <span class="mf">0.35</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$\mathcal</span><span class="si">{GP}</span><span class="s2">$ f or $\sigma_{\epsilon}=0.35$&quot;</span><span class="p">)</span>
<span class="n">gp_ax_plot</span><span class="p">(</span><span class="n">noise</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$\mathcal</span><span class="si">{GP}</span><span class="s2">$  for $\sigma_{\epsilon}=0.8$&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">gp_ax_plot</span><span class="p">(</span><span class="n">noise</span> <span class="o">=</span> <span class="mf">1.25</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$\mathcal</span><span class="si">{GP}</span><span class="s2">$ f or $\sigma_{\epsilon}=1.25$&quot;</span><span class="p">)</span>
<span class="n">gp_ax_plot</span><span class="p">(</span><span class="n">noise</span> <span class="o">=</span> <span class="mf">2.5</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$\mathcal</span><span class="si">{GP}</span><span class="s2">$  for $\sigma_{\epsilon}=2.5$&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/6934c2d0a9c5bb312e3c04c0d0a70a0f621037bd082915258b53374a70a14a22.png" src="../_images/6934c2d0a9c5bb312e3c04c0d0a70a0f621037bd082915258b53374a70a14a22.png" />
<img alt="../_images/54224e2fcec5a92e313bea7cec97480a226b006db9d43814e3f82badf0a979c6.png" src="../_images/54224e2fcec5a92e313bea7cec97480a226b006db9d43814e3f82badf0a979c6.png" />
</div>
</div>
<p>As the plot above illustrates severeal Gaussian Processes with different hyperparameters can give rise to a more or less meaningful result. To pin down only one it seems best to adhere to some optimality criterion for choosing some best fit to the given data.
For this the hyperparameters can be optimized via Maximum Likelihood estimation. To do this for the example data above we use the <code class="docutils literal notranslate"><span class="pre">GPytorch</span></code> package which uses pytorch and has similar syntax. We first define a model class similar to pytorch modules, but importantly the forward method will return a distribution (the predictive distributon of the input <span class="math notranslate nohighlight">\(x\)</span>, our query variable). We also define functions for training and testing(=prediction) which resembles a typical pytorch procedure (altough for neural networks).</p>
<div class="cell tag_hide-cell docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ExactGPModel</span><span class="p">(</span><span class="n">gpytorch</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">ExactGP</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This class implements a Gaussian Process.</span>
<span class="sd">    </span>
<span class="sd">    The model is based on the example from the package itself:</span>
<span class="sd">    (see: https://docs.gpytorch.ai/en/stable/examples/01_Exact_GPs/Simple_GP_Regression.html).</span>
<span class="sd">    A kernel class object is needed for the kernel and a likelihood object to specifiy the noise distribution $\epsilon$ of the actual data,</span>
<span class="sd">    e.g. $y_{i} = f(x_{i}) + \epsilon$.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">kernel</span><span class="p">):</span>
        
        <span class="n">x_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
        
        <span class="nb">super</span><span class="p">(</span><span class="n">ExactGPModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">means</span><span class="o">.</span><span class="n">ConstantMean</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">ScaleKernel</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">mean_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">covar_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">mean_x</span><span class="p">,</span> <span class="n">covar_x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">):</span>

    <span class="n">x_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
    
    <span class="n">mll</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">mlls</span><span class="o">.</span><span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">likelihood</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()}],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">mll</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
<span class="k">def</span> <span class="nf">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">as_df</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
    
    <span class="n">x_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">likelihood</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">pred_dist</span> <span class="o">=</span> <span class="n">likelihood</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span>
        <span class="n">pred_mean</span> <span class="o">=</span> <span class="n">pred_dist</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">pred_sd</span> <span class="o">=</span> <span class="n">pred_dist</span><span class="o">.</span><span class="n">stddev</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">as_df</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;pred&quot;</span><span class="p">:</span> <span class="n">pred_mean</span><span class="p">,</span> <span class="s2">&quot;sd&quot;</span><span class="p">:</span> <span class="n">pred_sd</span><span class="p">},</span> <span class="n">index</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        
    <span class="k">return</span> <span class="n">pred_mean</span><span class="p">,</span> <span class="n">pred_sd</span>

<span class="k">def</span> <span class="nf">get_hyperparam_df</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">df_old</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">prec</span> <span class="o">=</span> <span class="mi">4</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Shortcut function to extract the hyperparameters saved in parameter store of model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># columns with value for row &#39;model_name&#39;</span>
    <span class="n">param_names</span><span class="p">,</span> <span class="n">param_values</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()))</span>
    <span class="n">param_values</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span><span class="n">prec</span><span class="p">),</span> <span class="n">param_values</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">param_values</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="n">param_names</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="n">model_name</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">df_old</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">data</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">df_new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_old</span><span class="p">,</span> <span class="n">data</span><span class="p">])</span>
        <span class="n">df_new</span> <span class="o">=</span> <span class="n">df_new</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="n">df_old</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">fill_value</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">NA</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">df_new</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;&gt;:2: SyntaxWarning: invalid escape sequence &#39;\e&#39;
&lt;&gt;:2: SyntaxWarning: invalid escape sequence &#39;\e&#39;
/tmp/ipykernel_4012/2754476533.py:2: SyntaxWarning: invalid escape sequence &#39;\e&#39;
  &quot;&quot;&quot;
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">likelihoods</span><span class="o">.</span><span class="n">GaussianLikelihood</span><span class="p">()</span>
<span class="n">kernel_matern</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">MaternKernel</span><span class="p">(</span><span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span><span class="p">)</span>
<span class="n">kernel_rbf</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">RBFKernel</span><span class="p">()</span>

<span class="n">model_rbf</span> <span class="o">=</span> <span class="n">ExactGPModel</span><span class="p">(</span><span class="n">x_train</span> <span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">kernel_rbf</span><span class="p">)</span>
<span class="n">model_matern</span> <span class="o">=</span> <span class="n">ExactGPModel</span><span class="p">(</span><span class="n">x_train</span> <span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">kernel_matern</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_model</span><span class="p">(</span><span class="n">model_matern</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">train_model</span><span class="p">(</span><span class="n">model_rbf</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We trained two Gaussian Processes, one with a radial basis function kernel and one with a Matern kernel.
Below you can see the value of the optimal hyperparameters. <span class="math notranslate nohighlight">\(\sigma_{\epsilon}\)</span> is given by <code class="docutils literal notranslate"><span class="pre">likelihodd.noise_covar.raw_noise</span></code> both models seem to agree on its estimation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hypers</span> <span class="o">=</span> <span class="n">get_hyperparam_df</span><span class="p">(</span><span class="n">model_rbf</span><span class="p">,</span> <span class="s2">&quot;rbf&quot;</span><span class="p">,</span><span class="n">get_hyperparam_df</span><span class="p">(</span><span class="n">model_matern</span><span class="p">,</span> <span class="s2">&quot;matern&quot;</span><span class="p">))</span>
<span class="n">hypers</span><span class="p">[[</span><span class="s2">&quot;likelihood.noise_covar.raw_noise&quot;</span><span class="p">,</span> <span class="s2">&quot;covar_module.base_kernel.raw_lengthscale&quot;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>likelihood.noise_covar.raw_noise</th>
      <th>covar_module.base_kernel.raw_lengthscale</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>matern</th>
      <td>7.689</td>
      <td>0.067</td>
    </tr>
    <tr>
      <th>rbf</th>
      <td>7.689</td>
      <td>0.229</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now let us plot the result including a 95% confidence region for the predictive distribution:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">add_upper_lower</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">critical_value</span> <span class="o">=</span> <span class="mf">1.96</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Add upper and lower confidence bounds to data.</span>

<span class="sd">    Since the distribution is Gaussian mean and standard deviation are enough to get confidence bounds.</span>
<span class="sd">    By default this is the 5% confidence bound with a critical value of approx. 1.96.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="s2">&quot;pred&quot;</span><span class="p">,</span> <span class="s2">&quot;sd&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
    <span class="n">df_new</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">df_new</span><span class="p">[</span><span class="s2">&quot;upper&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_new</span><span class="p">[</span><span class="s2">&quot;pred&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">critical_value</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;sd&quot;</span><span class="p">]</span>
    <span class="n">df_new</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_new</span><span class="p">[</span><span class="s2">&quot;pred&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">critical_value</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;sd&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">df_new</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_rbf</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">model_rbf</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">x_line</span><span class="p">)</span>
<span class="n">data_rbf</span> <span class="o">=</span> <span class="n">add_upper_lower</span><span class="p">(</span><span class="n">data_rbf</span><span class="p">)</span>
<span class="n">data_rbf</span> <span class="o">=</span> <span class="n">concat_obs</span><span class="p">(</span><span class="n">data_rbf</span><span class="p">)</span>
<span class="n">estimated_noise</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">hypers</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;rbf&quot;</span><span class="p">][</span><span class="s2">&quot;likelihood.noise_covar.raw_noise&quot;</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data_rbf</span><span class="p">[</span><span class="s2">&quot;pred&quot;</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;blue&quot;</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;mean prediction, $\overline</span><span class="si">{f}</span><span class="s2">(x)$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data_rbf</span><span class="p">[</span><span class="s2">&quot;obs&quot;</span><span class="p">],</span> <span class="s2">&quot;rx&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;observation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y_data</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> <span class="s2">&quot;k-&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$f(x) =\sin (x)$&quot;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\mathcal</span><span class="si">{GP}</span><span class="s2">$ with RBF Kernel and $\hat{\sigma}_</span><span class="si">{n}</span><span class="s2">=estimated_noise$&quot;</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;estimated_noise&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">estimated_noise</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data_rbf</span><span class="p">[</span><span class="s2">&quot;upper&quot;</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;95</span><span class="si">% c</span><span class="s2">onfidence interval&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data_rbf</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">data_rbf</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">data_rbf</span><span class="p">[</span><span class="s2">&quot;upper&quot;</span><span class="p">],</span> <span class="n">data_rbf</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s2">&quot;upper left&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/42629389669afb445b69e98ba50f29bd57705b608eb1222ccb7c6378f307d13a.png" src="../_images/42629389669afb445b69e98ba50f29bd57705b608eb1222ccb7c6378f307d13a.png" />
</div>
</div>
<p>For further illustration we generate some new observations and inspect how the confidence interval changes as we sequentiall incorporate each new observation into our model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_samples</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">x_line_new</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="n">granularity</span><span class="p">)</span>
<span class="n">x_train_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">x_line_new</span><span class="p">,</span> <span class="n">new_samples</span><span class="p">,</span> <span class="n">replace</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">x_train_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">x_train_new</span><span class="p">)</span>
<span class="n">y_new_observed</span> <span class="o">=</span> <span class="n">add_error</span><span class="p">(</span><span class="n">true_func</span><span class="p">(</span><span class="n">x_train_new</span><span class="p">),</span> <span class="n">noise</span><span class="p">)</span>
<span class="n">x_line_updated</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_line</span><span class="p">,</span> <span class="n">x_line_new</span><span class="p">)</span>
<span class="n">new_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;y_new&quot;</span><span class="p">:</span> <span class="n">y_new_observed</span><span class="p">},</span> <span class="n">index</span> <span class="o">=</span> <span class="n">x_train_new</span><span class="p">)</span>
<span class="n">new_data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>y_new</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>20.902</th>
      <td>10.623</td>
    </tr>
    <tr>
      <th>21.343</th>
      <td>1.389</td>
    </tr>
    <tr>
      <th>21.523</th>
      <td>7.948</td>
    </tr>
    <tr>
      <th>21.864</th>
      <td>0.504</td>
    </tr>
    <tr>
      <th>25.050</th>
      <td>0.080</td>
    </tr>
    <tr>
      <th>25.671</th>
      <td>5.077</td>
    </tr>
    <tr>
      <th>28.377</th>
      <td>-3.977</td>
    </tr>
    <tr>
      <th>28.437</th>
      <td>-2.430</td>
    </tr>
    <tr>
      <th>28.477</th>
      <td>-2.775</td>
    </tr>
    <tr>
      <th>29.940</th>
      <td>-15.007</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Having sampled some new observations the plot below illustrates the new situation:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y_data</span><span class="p">[</span><span class="s2">&quot;y_train&quot;</span><span class="p">],</span> <span class="s2">&quot;rx&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$y_</span><span class="si">{obs}</span><span class="s2"> = f(x_</span><span class="si">{obs}</span><span class="s2">) + \epsilon$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">new_data</span><span class="p">[</span><span class="s2">&quot;y_new&quot;</span><span class="p">],</span> <span class="s2">&quot;rs&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$y_</span><span class="si">{new}</span><span class="s2"> = f(x_</span><span class="si">{new}</span><span class="s2">) + \epsilon$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;func&quot;</span><span class="p">:</span> <span class="n">true_func</span><span class="p">(</span><span class="n">x_line_updated</span><span class="p">)},</span> <span class="n">index</span> <span class="o">=</span> <span class="n">x_line_updated</span><span class="p">),</span> <span class="s2">&quot;k-&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$f(x) =\sin (x)$&quot;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$f(x)$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s2">&quot;upper left&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Old and new values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/241da001ec90e5604af873c495a66b3cf1ffdcf14275a26ee81e55f4fb676435.png" src="../_images/241da001ec90e5604af873c495a66b3cf1ffdcf14275a26ee81e55f4fb676435.png" />
</div>
</div>
<p>Now we refit our previous model each time one of the new data points is observed. The prediction for the remaining, unobserved data points would be the mean prediction indicated by the straight blue line.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set up initial data for which new data will be added and sequentially the model will be refitted.</span>

<span class="n">model_update</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">model_rbf</span><span class="p">)</span>
<span class="n">sequential_predictions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span> <span class="o">=</span> <span class="n">x_train_new</span><span class="p">)</span>
<span class="n">x_train_update</span> <span class="o">=</span> <span class="n">x_train</span>
<span class="n">y_train_update</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="n">x_line_update</span> <span class="o">=</span> <span class="n">x_line</span>

<span class="n">df_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">df_params</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">sequential_data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>     <span class="c1"># for 10 DataFrames of sequentially added observations to old ones</span>
<span class="n">sequential_models</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>  <span class="c1"># for 10 updated models with one new training point</span>

<span class="c1"># Now iterate obver each new observation...</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">new_obs</span><span class="p">,</span> <span class="n">new_x</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">y_new_observed</span><span class="p">,</span> <span class="n">x_train_new</span><span class="p">)):</span>
     <span class="c1"># ... and update the model and save intermediate data:</span>
    
    <span class="c1"># re-train model on updated data (in first iteration retrain again on same data)</span>
    <span class="n">model_update</span><span class="o">.</span><span class="n">set_train_data</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_train_update</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train_update</span><span class="p">),</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">train_model</span><span class="p">(</span><span class="n">model_update</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">x_train_update</span><span class="p">,</span> <span class="n">y_train_update</span><span class="p">)</span>
    
    <span class="c1"># adjust x axis to incorporate new data point</span>
    <span class="n">new_line_section</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x_line_update</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">new_x</span><span class="p">,</span> <span class="n">num</span> <span class="o">=</span> <span class="n">granularity</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    <span class="n">x_line_update</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_line_update</span><span class="p">,</span> <span class="n">new_line_section</span><span class="p">)</span>
    
    <span class="c1"># get prediction for new data point and old ones (adjusted due to new model training)</span>
    <span class="n">data_update</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">model_update</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">x_line_update</span><span class="p">)</span>
    
    <span class="n">df_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">add_upper_lower</span><span class="p">(</span><span class="n">data_update</span><span class="p">))</span>
    
    <span class="c1"># get model parameters</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;model_&quot;</span> <span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
    <span class="n">df_params</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_params</span><span class="p">,</span> <span class="n">get_hyperparam_df</span><span class="p">(</span><span class="n">model_update</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)])</span>
    
    <span class="n">x_train_update</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_train_update</span><span class="p">,</span> <span class="n">new_x</span><span class="p">)</span>
    <span class="n">y_train_update</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_train_update</span><span class="p">,</span> <span class="n">new_obs</span><span class="p">)</span>

    <span class="c1"># update data stream</span>
    <span class="n">sequential_models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model_update</span><span class="p">))</span>
    <span class="n">sequential_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">y_train_update</span><span class="p">},</span> <span class="n">index</span> <span class="o">=</span> <span class="n">x_train_update</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_plot</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Shortcut function to plot the results of each iteration from above.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">observations</span> <span class="o">=</span> <span class="n">sequential_data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="n">pred_idx</span> <span class="o">=</span> <span class="n">sequential_data</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">observations</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">sequential_data</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">pred_idx</span><span class="p">]</span>

    <span class="n">df_pred</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">sequential_models</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">x_line_update</span><span class="p">)</span>
    <span class="n">df_pred</span> <span class="o">=</span> <span class="n">add_upper_lower</span><span class="p">(</span><span class="n">df_pred</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;func&quot;</span><span class="p">:</span> <span class="n">true_func</span><span class="p">(</span><span class="n">x_line_updated</span><span class="p">)},</span> <span class="n">index</span> <span class="o">=</span> <span class="n">x_line_updated</span><span class="p">),</span> <span class="s2">&quot;k-&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$f(x) =\sin (x)$&quot;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; new prediction(s):&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">observations</span><span class="p">,</span> <span class="s2">&quot;rx&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;observations&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="s2">&quot;rs&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;predictions&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_pred</span><span class="p">[</span><span class="s2">&quot;pred&quot;</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;blue&quot;</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;mean prediction, $\overline</span><span class="si">{f}</span><span class="s2">(x)$&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_pred</span><span class="p">[</span><span class="s2">&quot;upper&quot;</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;95</span><span class="si">% c</span><span class="s2">onfidence interval&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_pred</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">df_pred</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">df_pred</span><span class="p">[</span><span class="s2">&quot;upper&quot;</span><span class="p">],</span> <span class="n">df_pred</span><span class="p">[</span><span class="s2">&quot;lower&quot;</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$x$&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$f(x)$&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s2">&quot;upper left&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ax</span>
 
</pre></div>
</div>
</div>
</details>
</div>
<p>Lets compare the intial situation with iteration with the situation where only the last red rectangle hasn’t been observed:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">make_plot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">make_plot</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/a6be3db05acf6d5a7777f7185334ef31540bdad589d2459f56574a5ebc5d7588.png" src="../_images/a6be3db05acf6d5a7777f7185334ef31540bdad589d2459f56574a5ebc5d7588.png" />
</div>
</div>
<p>The hyperparameters for both sezenarios are:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_params</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="s2">&quot;model_0&quot;</span><span class="p">,</span> <span class="s2">&quot;model_7&quot;</span><span class="p">]][[</span><span class="s2">&quot;likelihood.noise_covar.raw_noise&quot;</span><span class="p">,</span> <span class="s2">&quot;covar_module.base_kernel.raw_lengthscale&quot;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>likelihood.noise_covar.raw_noise</th>
      <th>covar_module.base_kernel.raw_lengthscale</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>model_0</th>
      <td>7.689</td>
      <td>0.411</td>
    </tr>
    <tr>
      <th>model_7</th>
      <td>7.689</td>
      <td>0.783</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The epistemic uncertainty as measured by <span class="math notranslate nohighlight">\(\sigma_{\epsilon}\)</span> did not change. But how about <span class="math notranslate nohighlight">\(\sigma_{i}\)</span> ?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_query</span> <span class="o">=</span> <span class="n">x_train_new</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="sa">r</span><span class="s2">&quot;$\sigma_</span><span class="si">{model_0}</span><span class="s2">$&quot;</span><span class="p">:</span>
               <span class="n">eval_model</span><span class="p">(</span><span class="n">sequential_models</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">likelihood</span> <span class="o">=</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x_query</span><span class="p">]))[</span><span class="s2">&quot;sd&quot;</span><span class="p">],</span>
               <span class="sa">r</span><span class="s2">&quot;$\sigma_</span><span class="si">{model_7}</span><span class="s2">$&quot;</span><span class="p">:</span>
               <span class="n">eval_model</span><span class="p">(</span><span class="n">sequential_models</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">likelihood</span> <span class="o">=</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x_query</span><span class="p">]))[</span><span class="s2">&quot;sd&quot;</span><span class="p">]</span>
              <span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>$\sigma_{model_0}$</th>
      <th>$\sigma_{model_7}$</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>28.477</th>
      <td>4.431</td>
      <td>3.638</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The aleatoric uncertainity decreased, but note that now the mean prediction curve seems to indicate some upward trend. And indeed if we look at the last red rectangle and refit again we get:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">make_plot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">make_plot</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/63f2c8293a0cd366beb9d930f28124dd338f9cf9d26f393f75d25c435142fa39.png" src="../_images/63f2c8293a0cd366beb9d930f28124dd338f9cf9d26f393f75d25c435142fa39.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_query</span> <span class="o">=</span> <span class="n">x_train_new</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="sa">r</span><span class="s2">&quot;$\sigma_</span><span class="si">{model_0}</span><span class="s2">$&quot;</span><span class="p">:</span>
               <span class="n">eval_model</span><span class="p">(</span><span class="n">sequential_models</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">likelihood</span> <span class="o">=</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x_query</span><span class="p">]))[</span><span class="s2">&quot;sd&quot;</span><span class="p">],</span>
               <span class="sa">r</span><span class="s2">&quot;$\sigma_</span><span class="si">{model_8}</span><span class="s2">$&quot;</span><span class="p">:</span>
               <span class="n">eval_model</span><span class="p">(</span><span class="n">sequential_models</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="n">likelihood</span> <span class="o">=</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x_query</span><span class="p">]))[</span><span class="s2">&quot;sd&quot;</span><span class="p">]</span>
              <span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>$\sigma_{model_0}$</th>
      <th>$\sigma_{model_8}$</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>29.940</th>
      <td>4.431</td>
      <td>4.837</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The aleartoric uncertainty in our last query point has actually increased after taking into account the previous observations. <br>
Finally lets show the overal process of updating the model sequentially to the new data points:</p>
<p><img alt="" src="../_images/sequential_gp.gif" /></p>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter-gaussianprocess"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../chapter-generative_models/gm.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">9. </span>Generative Models</p>
      </div>
    </a>
    <a class="right-next"
       href="../chapter-deep_neuralnetwork/dnn.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">11. </span>Deep Neural Network Ensembles</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <section>
    For comprehensive discussions please contact one of our team members: 
    {Evert.Buzon,Jiawen.Wang,Nico.Ploehn,S.Thies,Sven.Morlock,Zuo.Longfei}@campus.lmu.de

        <div style="margin-top: 50px;" id="disqus_thread"></div>

        <script>
            (function() { 
                var d = document, s = d.createElement('script');
                s.src = 'https://https-werywjw-github-io-toolbox-github-io.disqus.com/embed.js';  
                s.setAttribute('data-timestamp', +new Date());
                (d.head || d.body).appendChild(s);
        })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </section> 

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>