{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proper Scoring Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "[Scoring Rules](https://en.wikipedia.org/wiki/Scoring_rule) assess the quality of probabilistic forecasts, by assigning a numerical score based on the predictive distribution and on the event or value that materializes. A scoring rule is proper if the forecaster maximizes the expected score for an observation drawn from the distribution $F$ if he or she issues the probabilistic forecast $F$, rather than $G \\neq F$. It is strictly proper if the maximum is unique. In prediction problems, proper scoring rules encourage the forecaster to make careful assessments and to be honest. In estimation problems, strictly proper scoring rules provide attractive loss and utility functions that can be tailored to the problem at hand ({cite:t}`gnei_sp05`).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Ranked Probability Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "The Continuous Ranked Probability Score (CRPS) applies to probabilistic forecasts that take the form of predictive cumulative distribution functions. It generalizes the absolute error and forms a special case of a new and very general type of score, the energy score. Like many other scoring rules, the energy score admits a kernel representation in terms of negative definite functions, with links to inequalities of Hoeffding type, in both univariate and multivariate settings ({cite:t}`gnei_sp05`). \n",
    "\n",
    "The CRPS is defined as follows:\n",
    "\n",
    "$$\n",
    "\\text{CRPS}(F,x) = \\int_{-\\infty}^{\\infty} \\left( F(y) - \\mathbf{1}\\{y \\geq x\\} \\right)^2 \\, dy,\n",
    "$$\n",
    "\n",
    "where $F$ is the cumulative distribution function (CDF) of the forecast, $x$ is the observed value, and $\\mathbf{1}\\{y \\geq x\\}$ is the indicator function, which is 1 if $y \\geq x$ and 0 otherwise. \n",
    "\n",
    "For a Gaussian (normal) predictive distribution with mean $\\mu$ and standard deviation $\\sigma$, \n",
    "the CRPS can be computed using a closed-form solution:\n",
    "\n",
    "$$\n",
    "\\text{CRPS}(F, x) = \\sigma \\left[ \\frac{x - \\mu}{\\sigma} \\left( 2\\Phi\\left( \\frac{x - \\mu}{\\sigma} \\right) - 1 \\right) + 2\\phi\\left( \\frac{x - \\mu}{\\sigma} \\right) - \\frac{1}{\\sqrt{\\pi}} \\right], \n",
    "$$\n",
    "\n",
    "where $\\Phi$ is the CDF of the standard normal distribution and $\\phi$ is the probability density function (PDF) of the standard normal distribution.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crps(y_true, y_pred):\n",
    "    residuals = y_true - y_pred\n",
    "    y_std = np.std(residuals)\n",
    "    crps_values = []\n",
    "    for i in range(len(y_true)):\n",
    "        mu = y_pred[i]\n",
    "        sigma = y_std\n",
    "        obs = y_true[i]\n",
    "        term1 = np.abs(obs - mu)\n",
    "        term2 = sigma * (1 / np.sqrt(np.pi))\n",
    "        crps_value = term1 + term2 - 2 * sigma * norm.cdf((obs - mu) / sigma)\n",
    "        crps_values.append(crps_value)\n",
    "    return np.mean(crps_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brier Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "The [Brier Score](https://en.wikipedia.org/wiki/Brier_score) (Quadratic Score) is a strictly proper scoring rule which measures the accuracy of probabilistic predictions, \n",
    "\n",
    "$$\n",
    "S_{\\text{Brier}}= \\frac{1}{N} \\sum_{i=1}^N (p_i-y_i)^2.\n",
    "$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brier_score(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    return np.mean((y_pred - y_true) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "```{note}\n",
    "The Brier score can be thought of as a cost function. Thus lower values indicate better performance. \n",
    "In its most common formulation, it takes on a value between 0 and 1, \n",
    "since this is the square of the largest possible difference between a predicted probability and the actual outcome. \n",
    "The Brier score is appropriate for binary and categorical outcomes that can be structured as true or false, \n",
    "but it is inappropriate for ordinal variables which can take on three or more values.\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logarithmic Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "The Logarithmic (Log) Score is also often used in the context of probability forecasting, \n",
    "\n",
    "$$\n",
    "S_{\\text{Log}} = -\\sum_{i=1}^N y_i \\log(p_i).\n",
    "$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logarithmic_score(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    return -np.sum(y_true * np.log(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "It measures the performance of a classification model where the prediction is a probability value between 0 and 1, \n",
    "\n",
    "$$\n",
    "L = -\\frac{1}{N} \\sum_{i=1}^N \\left(y_i \\log(p_i) + (1-y_i) \\log(1-p_i) \\right).\n",
    "$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "```{hint}\n",
    "The Log Loss, Logarithmic Loss, Logistic Loss, and Cross-entropy Loss are used interchangeably. \n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Square Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "In statistics, the [mean squared error (MSE)](https://en.wikipedia.org/wiki/Mean_squared_error) or mean squared deviation (MSD) of an estimator (of a procedure for estimating an unobserved quantity) measures the average of the squares of the errors,\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N (\\hat{y_i}-y_i)^2.\n",
    "$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    return np.mean((y_pred - y_true) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "```{note}\n",
    "The Mean Squared Error is a more general measure of accuracy, used primarily in regression tasks. \n",
    "It measures the average of the squares of the differences between predicted values and actual values. \n",
    "While the Brier Score is used specifically for probabilistic predictions in binary classification tasks. \n",
    "It measures the mean squared difference between predicted probabilities and the actual binary outcomes.\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "R-squared (coefficient of determination) measures the proportion of the variance in the dependent variable that is predictable from the independent variables, \n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^N (y_i-\\hat{y_i})^2}{\\sum_{i=1}^N (y_i-\\bar{y_i})^2}.\n",
    "$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(y_true, y_pred):\n",
    "    error = y_pred - y_true\n",
    "    sse = (error ** 2).sum()\n",
    "    tss = ((y_true - y_true.mean()) ** 2).sum()    \n",
    "    return 1 - sse / tss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "```{note}\n",
    "$N$ denotes the number of observations or data points in the dataset.\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
